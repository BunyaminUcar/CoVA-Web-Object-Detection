{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from datasets import WebDataset\n",
    "from models import WebObjExtractionNet\n",
    "from train import train_model, evaluate_model\n",
    "from utils import custom_collate_fn, count_parameters, pkl_load\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "N_CLASSES = 4 # 0: BG, 1: Price, 2: Image, 3: Title\n",
    "IMG_HEIGHT = 1280 # Image assumed to have same height and width\n",
    "EVAL_INTERVAL = 5 # Number of Epochs after which model is evaluated\n",
    "\n",
    "# Hyperparameters\n",
    "BATCH_SIZE = 10\n",
    "ROI_POOL_OUTPUT_SIZE = (5,5)\n",
    "TRAINABLE_CONVNET = False\n",
    "LEARNING_RATE = 1e-3\n",
    "N_EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = WebDataset('../data/web_data/train')\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4,\n",
    "                          collate_fn=custom_collate_fn, drop_last=False)\n",
    "\n",
    "test_dataset = WebDataset('../data/web_data/test')\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=4,\n",
    "                         collate_fn=custom_collate_fn, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Images: 4891\n",
      "Test  Images: 1129\n"
     ]
    }
   ],
   "source": [
    "print('Train Images:', len(train_dataset))\n",
    "print('Test  Images:', len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing WebObjExtractionNet model...\n",
      "Using first few layers of Resnet18 as ConvNet Visual Feature Extractor\n",
      "ConvNet weights Freezed\n",
      "ConvNet Feature Map size: torch.Size([1, 64, 320, 320])\n",
      "WebObjExtractionNet(\n",
      "  (convnet): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (4): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (roi_pool): RoIPool(output_size=(5, 5), spatial_scale=0.25)\n",
      "  (fc): Linear(in_features=1600, out_features=4, bias=True)\n",
      ")\n",
      "--------------------------------------------------\n",
      "Trainable parameters in model: 6404\n",
      "Training Model for 20 epochs...\n",
      "[TRAIN]\t Epoch:  1\t Loss: 0.2326\t Accuracy: 96.99% (117.91s)\n",
      "[EVAL]\t Loss: 0.1932\t Accuracy: 97.15% (28.51s)\n",
      "Class 0: Accuracy: 99.84%\n",
      "Class 1: Accuracy: 0.35%\n",
      "Class 2: Accuracy: 1.15%\n",
      "Class 3: Accuracy: 27.10%\n",
      "\n",
      "[TRAIN]\t Epoch:  2\t Loss: 0.1709\t Accuracy: 97.26% (116.39s)\n",
      "[TRAIN]\t Epoch:  3\t Loss: 0.1441\t Accuracy: 97.39% (116.07s)\n",
      "[TRAIN]\t Epoch:  4\t Loss: 0.1280\t Accuracy: 97.46% (115.77s)\n",
      "[TRAIN]\t Epoch:  5\t Loss: 0.1175\t Accuracy: 97.51% (116.08s)\n",
      "[EVAL]\t Loss: 0.1254\t Accuracy: 97.45% (29.37s)\n",
      "Class 0: Accuracy: 99.73%\n",
      "Class 1: Accuracy: 13.99%\n",
      "Class 2: Accuracy: 15.06%\n",
      "Class 3: Accuracy: 40.39%\n",
      "\n",
      "[TRAIN]\t Epoch:  6\t Loss: 0.1112\t Accuracy: 97.55% (118.82s)\n",
      "[TRAIN]\t Epoch:  7\t Loss: 0.1064\t Accuracy: 97.59% (119.05s)\n",
      "[TRAIN]\t Epoch:  8\t Loss: 0.1038\t Accuracy: 97.62% (118.54s)\n",
      "[TRAIN]\t Epoch:  9\t Loss: 0.1007\t Accuracy: 97.65% (115.60s)\n",
      "[TRAIN]\t Epoch: 10\t Loss: 0.1000\t Accuracy: 97.64% (117.06s)\n",
      "[EVAL]\t Loss: 0.1265\t Accuracy: 97.36% (28.03s)\n",
      "Class 0: Accuracy: 99.89%\n",
      "Class 1: Accuracy: 6.55%\n",
      "Class 2: Accuracy: 11.78%\n",
      "Class 3: Accuracy: 27.19%\n",
      "\n",
      "[TRAIN]\t Epoch: 11\t Loss: 0.0981\t Accuracy: 97.66% (115.82s)\n",
      "[TRAIN]\t Epoch: 12\t Loss: 0.0965\t Accuracy: 97.69% (119.21s)\n",
      "[TRAIN]\t Epoch: 13\t Loss: 0.0947\t Accuracy: 97.72% (117.11s)\n",
      "[TRAIN]\t Epoch: 14\t Loss: 0.0950\t Accuracy: 97.71% (115.36s)\n",
      "[TRAIN]\t Epoch: 15\t Loss: 0.0939\t Accuracy: 97.71% (115.99s)\n",
      "[EVAL]\t Loss: 0.1177\t Accuracy: 97.37% (27.62s)\n",
      "Class 0: Accuracy: 99.49%\n",
      "Class 1: Accuracy: 16.74%\n",
      "Class 2: Accuracy: 14.53%\n",
      "Class 3: Accuracy: 52.88%\n",
      "\n",
      "[TRAIN]\t Epoch: 16\t Loss: 0.0936\t Accuracy: 97.74% (116.42s)\n",
      "[TRAIN]\t Epoch: 17\t Loss: 0.0938\t Accuracy: 97.71% (116.82s)\n",
      "[TRAIN]\t Epoch: 18\t Loss: 0.0930\t Accuracy: 97.73% (119.26s)\n",
      "[TRAIN]\t Epoch: 19\t Loss: 0.0927\t Accuracy: 97.75% (117.78s)\n",
      "[TRAIN]\t Epoch: 20\t Loss: 0.0926\t Accuracy: 97.73% (119.10s)\n",
      "[EVAL]\t Loss: 0.1278\t Accuracy: 97.40% (29.06s)\n",
      "Class 0: Accuracy: 99.90%\n",
      "Class 1: Accuracy: 8.68%\n",
      "Class 2: Accuracy: 9.57%\n",
      "Class 3: Accuracy: 30.47%\n",
      "\n",
      "Model Trained!\n"
     ]
    }
   ],
   "source": [
    "model = WebObjExtractionNet(ROI_POOL_OUTPUT_SIZE, IMG_HEIGHT, N_CLASSES, TRAINABLE_CONVNET).to(device)\n",
    "print('Trainable parameters in model:', count_parameters(model))\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "criterion = nn.CrossEntropyLoss(reduction='sum').to(device)\n",
    "\n",
    "model = train_model(model, train_loader, optimizer, criterion, N_EPOCHS, device, test_loader, EVAL_INTERVAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
