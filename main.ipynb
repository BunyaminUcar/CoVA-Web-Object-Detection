{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from datasets import WebDataset\n",
    "from models import WebObjExtractionNet\n",
    "from train import train_model, evaluate_model\n",
    "from utils import custom_collate_fn, pkl_load, print_and_log\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "# torch.backends.cudnn.deterministic = True\n",
    "# torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "N_CLASSES = 4 # 0: BG, 1: Price, 2: Image, 3: Title\n",
    "CLASS_NAMES = ['BG', 'Price', 'Image', 'Title']\n",
    "IMG_HEIGHT = 1280 # Image assumed to have same height and width\n",
    "EVAL_INTERVAL = 5 # Number of Epochs after which model is evaluated\n",
    "TRAIN_DATA_DIR = '../data/web_data/train'\n",
    "TEST_DATA_DIR = '../data/web_data/test'\n",
    "OUTPUT_DIR = 'results'\n",
    "\n",
    "# Hyperparameters\n",
    "N_EPOCHS = 20\n",
    "LEARNING_RATE = 1e-3\n",
    "BACKBONE = 'alexnet' # 'resnet'\n",
    "BATCH_SIZE = 50\n",
    "ROI_POOL_OUTPUT_SIZE = (3,3)\n",
    "TRAINABLE_CONVNET = True\n",
    "WEIGHTED_LOSS = False\n",
    "\n",
    "if WEIGHTED_LOSS:\n",
    "    WEIGHTS = torch.Tensor([1,100,100,100]) # weight inversely proportional to number of examples for the class\n",
    "    print('Weighted loss with class weights:', WEIGHTS)\n",
    "else:\n",
    "    WEIGHTS = torch.ones(N_CLASSES)\n",
    "\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)\n",
    "\n",
    "# NOTE: if same hyperparameter configuration is run again, previous log file will be overwritten\n",
    "LOG_FILE = '%s/logs %s batch-%d roi-%d lr-%.0e wt_loss-%d.txt' % (OUTPUT_DIR, BACKBONE, BATCH_SIZE, ROI_POOL_OUTPUT_SIZE[0],\n",
    "                                                                  LEARNING_RATE, WEIGHTED_LOSS)\n",
    "print('logs will be saved in \\\"%s\\\"' % (LOG_FILE))\n",
    "print_and_log('Batch Size: %d' % (BATCH_SIZE), LOG_FILE, 'w')\n",
    "print_and_log('RoI Pool Output Size: (%d, %d)' % ROI_POOL_OUTPUT_SIZE, LOG_FILE)\n",
    "print_and_log('Learning Rate: %.0e\\n' % (LEARNING_RATE), LOG_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = WebDataset(TRAIN_DATA_DIR)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4,\n",
    "                          collate_fn=custom_collate_fn, drop_last=False)\n",
    "\n",
    "test_dataset = WebDataset(TEST_DATA_DIR)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=4,\n",
    "                         collate_fn=custom_collate_fn, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train Images:', len(train_dataset))\n",
    "print('Test  Images:', len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = WebObjExtractionNet(ROI_POOL_OUTPUT_SIZE, IMG_HEIGHT, N_CLASSES, BACKBONE, TRAINABLE_CONVNET, CLASS_NAMES).to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "criterion = nn.CrossEntropyLoss(weight=WEIGHTS, reduction='sum').to(device)\n",
    "\n",
    "model = train_model(model, train_loader, optimizer, criterion, N_EPOCHS, device, test_loader, EVAL_INTERVAL, LOG_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
