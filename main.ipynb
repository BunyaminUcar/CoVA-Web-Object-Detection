{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from datasets import WebDataset\n",
    "from models import WebObjExtractionNet\n",
    "from train import train_model, evaluate_model\n",
    "from utils import custom_collate_fn, pkl_load, print_and_log\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f362eb0d130>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 1\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "# torch.backends.cudnn.deterministic = True\n",
    "# torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs will be saved in \"results/logs alexnet batch-50 roi-3 lr-1e-03 wt_loss-0.txt\"\n",
      "Batch Size: 50\n",
      "RoI Pool Output Size: (3, 3)\n",
      "Learning Rate: 1e-03\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "N_CLASSES = 4 # 0: BG, 1: Price, 2: Image, 3: Title\n",
    "CLASS_NAMES = ['BG', 'Price', 'Image', 'Title']\n",
    "IMG_HEIGHT = 1280 # Image assumed to have same height and width\n",
    "EVAL_INTERVAL = 5 # Number of Epochs after which model is evaluated\n",
    "TRAIN_DATA_DIR = '../data/web_data/train'\n",
    "TEST_DATA_DIR = '../data/web_data/test'\n",
    "OUTPUT_DIR = 'results'\n",
    "\n",
    "# Hyperparameters\n",
    "N_EPOCHS = 20\n",
    "LEARNING_RATE = 1e-3\n",
    "BACKBONE = 'alexnet' # 'resnet'\n",
    "BATCH_SIZE = 50\n",
    "ROI_POOL_OUTPUT_SIZE = (3,3)\n",
    "TRAINABLE_CONVNET = True\n",
    "WEIGHTED_LOSS = False\n",
    "\n",
    "if WEIGHTED_LOSS:\n",
    "    WEIGHTS = torch.Tensor([1,100,100,100]) # weight inversely proportional to number of examples for the class\n",
    "    print('Weighted loss with class weights:', WEIGHTS)\n",
    "else:\n",
    "    WEIGHTS = torch.ones(N_CLASSES)\n",
    "\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)\n",
    "\n",
    "# NOTE: if same hyperparameter configuration is run again, previous log file will be overwritten\n",
    "LOG_FILE = '%s/logs %s batch-%d roi-%d lr-%.0e wt_loss-%d.txt' % (OUTPUT_DIR, BACKBONE, BATCH_SIZE, ROI_POOL_OUTPUT_SIZE[0],\n",
    "                                                                  LEARNING_RATE, WEIGHTED_LOSS)\n",
    "print('logs will be saved in \\\"%s\\\"' % (LOG_FILE))\n",
    "print_and_log('Batch Size: %d' % (BATCH_SIZE), LOG_FILE, 'w')\n",
    "print_and_log('RoI Pool Output Size: (%d, %d)' % ROI_POOL_OUTPUT_SIZE, LOG_FILE)\n",
    "print_and_log('Learning Rate: %.0e\\n' % (LEARNING_RATE), LOG_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = WebDataset(TRAIN_DATA_DIR)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4,\n",
    "                          collate_fn=custom_collate_fn, drop_last=False)\n",
    "\n",
    "test_dataset = WebDataset(TEST_DATA_DIR)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4,\n",
    "                         collate_fn=custom_collate_fn, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Images: 4891\n",
      "Test  Images: 1129\n"
     ]
    }
   ],
   "source": [
    "print('Train Images:', len(train_dataset))\n",
    "print('Test  Images:', len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing WebObjExtractionNet model...\n",
      "Using first few layers of \"alexnet\" as ConvNet Visual Feature Extractor\n",
      "ConvNet Feature Map size: torch.Size([1, 384, 79, 79])\n",
      "Trainable parameters: 1008452\n",
      "WebObjExtractionNet(\n",
      "  (convnet): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (roi_pool): RoIPool(output_size=(3, 3), spatial_scale=0.06171875)\n",
      "  (fc): Linear(in_features=3456, out_features=4, bias=True)\n",
      ")\n",
      "--------------------------------------------------\n",
      "Training Model for 20 epochs...\n",
      "[TRAIN]\t Epoch:  1\t Loss: 0.3520\t Accuracy: 94.00% (118.36s)\n",
      "[EVAL]\t Loss: 0.1856\t Accuracy: 97.26% (31.81s)\n",
      "True \\ Pred\tBG\tPrice\tImage\tTitle\n",
      "BG\t\t110149\t10\t23\t121\n",
      "Price\t\t1067\t62\t0\t0\n",
      "Image\t\t1020\t0\t103\t6\n",
      "Title\t\t871\t0\t0\t258\n",
      "\n",
      "   BG Acc: 99.86%\n",
      "Price Acc: 5.49%\n",
      "Image Acc: 9.12%\n",
      "Title Acc: 22.85%\n",
      "\n",
      "[TRAIN]\t Epoch:  2\t Loss: 0.1564\t Accuracy: 97.42% (117.08s)\n",
      "[TRAIN]\t Epoch:  3\t Loss: 0.1364\t Accuracy: 97.77% (123.17s)\n",
      "[TRAIN]\t Epoch:  4\t Loss: 0.1212\t Accuracy: 98.09% (116.82s)\n",
      "[TRAIN]\t Epoch:  5\t Loss: 0.1133\t Accuracy: 98.22% (116.65s)\n",
      "[EVAL]\t Loss: 0.1369\t Accuracy: 97.85% (31.08s)\n",
      "True \\ Pred\tBG\tPrice\tImage\tTitle\n",
      "BG\t\t110113\t80\t28\t82\n",
      "Price\t\t782\t347\t0\t0\n",
      "Image\t\t793\t10\t326\t0\n",
      "Title\t\t675\t0\t0\t454\n",
      "\n",
      "   BG Acc: 99.83%\n",
      "Price Acc: 30.74%\n",
      "Image Acc: 28.88%\n",
      "Title Acc: 40.21%\n",
      "\n",
      "[TRAIN]\t Epoch:  6\t Loss: 0.1010\t Accuracy: 98.48% (124.31s)\n",
      "[TRAIN]\t Epoch:  7\t Loss: 0.0926\t Accuracy: 98.62% (117.45s)\n",
      "[TRAIN]\t Epoch:  8\t Loss: 0.0851\t Accuracy: 98.75% (120.28s)\n",
      "[TRAIN]\t Epoch:  9\t Loss: 0.0782\t Accuracy: 98.86% (116.53s)\n",
      "[TRAIN]\t Epoch: 10\t Loss: 0.0731\t Accuracy: 98.90% (116.34s)\n",
      "[EVAL]\t Loss: 0.1102\t Accuracy: 98.04% (30.43s)\n",
      "True \\ Pred\tBG\tPrice\tImage\tTitle\n",
      "BG\t\t109698\t137\t87\t381\n",
      "Price\t\t637\t490\t1\t1\n",
      "Image\t\t608\t1\t520\t0\n",
      "Title\t\t381\t0\t0\t748\n",
      "\n",
      "   BG Acc: 99.45%\n",
      "Price Acc: 43.40%\n",
      "Image Acc: 46.06%\n",
      "Title Acc: 66.25%\n",
      "\n",
      "[TRAIN]\t Epoch: 11\t Loss: 0.0661\t Accuracy: 99.03% (117.41s)\n",
      "[TRAIN]\t Epoch: 12\t Loss: 0.0610\t Accuracy: 99.11% (118.85s)\n",
      "[TRAIN]\t Epoch: 13\t Loss: 0.0567\t Accuracy: 99.15% (121.62s)\n",
      "[TRAIN]\t Epoch: 14\t Loss: 0.0524\t Accuracy: 99.21% (117.98s)\n",
      "[TRAIN]\t Epoch: 15\t Loss: 0.0504\t Accuracy: 99.20% (117.23s)\n",
      "[EVAL]\t Loss: 0.1039\t Accuracy: 97.99% (32.65s)\n",
      "True \\ Pred\tBG\tPrice\tImage\tTitle\n",
      "BG\t\t109684\t160\t55\t404\n",
      "Price\t\t555\t573\t0\t1\n",
      "Image\t\t698\t6\t425\t0\n",
      "Title\t\t410\t0\t0\t719\n",
      "\n",
      "   BG Acc: 99.44%\n",
      "Price Acc: 50.75%\n",
      "Image Acc: 37.64%\n",
      "Title Acc: 63.68%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = WebObjExtractionNet(ROI_POOL_OUTPUT_SIZE, IMG_HEIGHT, N_CLASSES, BACKBONE, TRAINABLE_CONVNET, CLASS_NAMES).to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "criterion = nn.CrossEntropyLoss(weight=WEIGHTS, reduction='sum').to(device)\n",
    "\n",
    "model = train_model(model, train_loader, optimizer, criterion, N_EPOCHS, device, test_loader, EVAL_INTERVAL, LOG_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
