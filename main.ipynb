{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from datasets import load_data\n",
    "from models import WebObjExtractionNet\n",
    "from train import train_model, evaluate_model\n",
    "from utils import print_and_log\n",
    "\n",
    "DEVICE_NO = 0\n",
    "device = torch.device('cuda:%d' % DEVICE_NO if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## MAKING RESULTS REPRODUCIBLE ##########\n",
    "seed = 1\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "# torch.backends.cudnn.deterministic = True\n",
    "# torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## PARAMETERS ##########\n",
    "N_CLASSES = 4\n",
    "CLASS_NAMES = ['BG', 'Price', 'Image', 'Title']\n",
    "IMG_HEIGHT = 1280 # Image assumed to have same height and width\n",
    "EVAL_INTERVAL = 5 # Number of Epochs after which model is evaluated\n",
    "NUM_WORKERS = 6 # multithreaded data loading\n",
    "\n",
    "DATA_DIR = '../data/' # Contains .png and .pkl files for train and test data\n",
    "OUTPUT_DIR = 'results' # logs are saved here! \n",
    "# NOTE: if same hyperparameter configuration is run again, previous log file and saved model will be overwritten\n",
    "\n",
    "SPLIT_DIR = 'splits/random' # contains train, val, test split files\n",
    "# each line in these files should contain name of the training image (without file extension)\n",
    "TRAIN_SPLIT_ID_FILE = SPLIT_DIR+ '/train_imgs.txt'\n",
    "VAL_SPLIT_ID_FILE = SPLIT_DIR + '/val_imgs.txt'\n",
    "TEST_SPLIT_ID_FILE = SPLIT_DIR + '/test_imgs.txt'\n",
    "\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)\n",
    "    \n",
    "train_img_ids = np.loadtxt(TRAIN_SPLIT_ID_FILE, dtype=np.int32)\n",
    "val_img_ids = np.loadtxt(VAL_SPLIT_ID_FILE, dtype=np.int32)\n",
    "test_img_ids = np.loadtxt(TEST_SPLIT_ID_FILE, dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## HYPERPARAMETERS ##########\n",
    "N_EPOCHS = 50\n",
    "BACKBONE = 'alexnet'\n",
    "TRAINABLE_CONVNET = True\n",
    "LEARNING_RATE = 5e-4\n",
    "BATCH_SIZE = 50\n",
    "WEIGHT_DECAY = 0.0\n",
    "ROI_POOL_OUTPUT_SIZE = (3,3)\n",
    "WEIGHTED_LOSS = False\n",
    "POS_FEAT = True\n",
    "\n",
    "if WEIGHTED_LOSS:\n",
    "    weights = torch.Tensor([1,100,100,100]) # weight inversely proportional to number of examples for the class\n",
    "    print('Weighted loss with class weights:', weights)\n",
    "else:\n",
    "    weights = torch.ones(N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = '%s lr-%.0e batch-%d wd-%.0e roi-%d wt_loss-%d pf-%d' % (BACKBONE, LEARNING_RATE, BATCH_SIZE, WEIGHT_DECAY, ROI_POOL_OUTPUT_SIZE[0], WEIGHTED_LOSS, POS_FEAT)\n",
    "log_file = '%s/%s logs.txt' % (OUTPUT_DIR, params)\n",
    "model_save_file = '%s/%s saved_model.pth' % (OUTPUT_DIR, params)\n",
    "\n",
    "print('logs will be saved in \\\"%s\\\"' % (log_file))\n",
    "print_and_log('Backbone Convnet: %s' % (BACKBONE), log_file, 'w')\n",
    "print_and_log('Trainable Convnet: %s' % (TRAINABLE_CONVNET), log_file)\n",
    "print_and_log('Learning Rate: %.0e' % (LEARNING_RATE), log_file)\n",
    "print_and_log('Batch Size: %d' % (BATCH_SIZE), log_file)\n",
    "print_and_log('Weight Decay: %.0e' % (WEIGHT_DECAY), log_file)\n",
    "print_and_log('RoI Pool Output Size: (%d, %d)' % ROI_POOL_OUTPUT_SIZE, log_file)\n",
    "print_and_log('Weighted Loss: %s' % (WEIGHTED_LOSS), log_file)\n",
    "print_and_log('Position Features: %s\\n' % (POS_FEAT), log_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## DATA LOADERS ##########\n",
    "train_loader, val_loader, test_loader = load_data(DATA_DIR, train_img_ids, val_img_ids, test_img_ids, BATCH_SIZE, NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## CREATE MODEL & LOSS FN ##########\n",
    "model = WebObjExtractionNet(ROI_POOL_OUTPUT_SIZE, IMG_HEIGHT, N_CLASSES, BACKBONE, TRAINABLE_CONVNET, POS_FEAT, CLASS_NAMES).to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "criterion = nn.CrossEntropyLoss(weight=weights, reduction='sum').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## TRAIN MODEL ##########\n",
    "train_model(model, train_loader, optimizer, criterion, N_EPOCHS, device, val_loader, EVAL_INTERVAL, log_file, 'ckpt_%d.pth' % args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## EVALUATE TEST PERFORMANCE ##########\n",
    "evaluate_model(model, test_loader, criterion, device, 'TEST', log_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## SAVE MODEL ##########\n",
    "torch.save(model.state_dict(), model_save_file)\n",
    "print_and_log('Model can be restored from \\\"%s\\\"' % (model_save_file), log_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
